{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:18.982585Z",
     "start_time": "2024-11-14T19:29:18.967681Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import date\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# константы\n",
    "RANDOM_STATE = 5\n",
    "DATA_PATH = '../data'\n",
    "COOCIE_NB = '_csrf_token=322d41e9006e0d84d35ea2ba160ffb0edcaf8bde6af076a0; suid=d5b39f92ec07e14b5ede65193afae8dd.b7a4c96080bd260714d8bcd31af9fb4a; autoruuid=g671fe5f02tuv4stgtm003ft6ufjgtuf.cf4d48bce1d92127b1dc5420a6c012d3; from=direct; autoru_sso_blocked=1; Session_id=3:1730143729.5.0.1729626845318:0EzFWw:1e52.1.2:1|1130000067438128.-1.0.3:1729626845|61:10026972.494636.G47KJoJnrGleXdU3AV1aAbBSOIE; sessar=1.1195.CiC4kiZ9xgGyA9EKYOSeDcPovH-CImZprpSTDFCpFXMUfQ.JxIZidV8vdomSfagoec4_A7vSfKJYsUeVx-hqv85aII; yandex_login=daboldyrev@edu.hse.ru; ys=udn.cDpkYWJvbGR5cmV2QGVkdS5oc2UucnU%3D#c_chck.1929241363; i=tlhDxtDyQeSf93G4Sd2jN8QeRk4YamYpZXEiLrhQS7CLpw0+5vhEzZB3fpv6+DoEc80kD0DF7VDIIgjCNuTIizOlOu8=; yandexuid=2160422051564510217; my=YwA=; L=Xy5fSWVnBHIJSEN2UVlaRQ5hWW9bXVoGIFYzOSssLABdEC9SECxcJxsSVytC.1729626845.15927.340609.84c416984beb9e0cf870a4d6f92acb61; mda2_beacon=1730143729098; sso_status=sso.passport.yandex.ru:synchronized; autoru_sso_redirect_blocked=1; _ym_uid=1684353637548378497; yaPassportTryAutologin=1; _ym_isad=2; autoru_sid=123729954%7C1730143739148.7776000.b4c5nf1yViUEOZ-QftLYSw.mUjU3EqWVT1cPoNPBDcE6l2ZGA5w6n6ifxDp-_Y12Pc; _yasc=+J+VIii3pr3WbEOhoe+sjg44LQZA886gpGdnqTZiAIEC+O3+kkAC+EqS5keXehajStIA; popups-popup-guess-the-car-shown-count=1; _ym_d=1730145169; count-visits=4; from_lifetime=1730145175566; layout-config={\"screen_height\":1080,\"screen_width\":1920,\"win_width\":334,\"win_height\":983}; cycada=Crddb5c+sUwEnCqwO6jVWnYzs+eP5+y9mEaD7l6eSdg='\n",
    "\n",
    "COOCIE_PC = '_ym_uid=1730325262421443420; _ym_isad=2; gdpr=0; _ym_visorc=b; spravka=dD0xNzMwMzI1Mjc3O2k9MTc4LjIzNC4xOS4yMDI7RD1GNjQ4OUE1NTVBQTBCMjE4MzAxOUU4RUREOTA1NkIyM0UxQTRGMTI1RDc0NTE1NTU1MzBEOTA4OUNFQzRBNDcwNzBFQjExRUU4QTVFNzUxNUUyNzRFNzFGOEE2REZFRDhCNzhCRUUzQkIzNjAwNjg0NkRGMDAxNUM1NkM2QjY0RkY3Qjg0RURDMUQ7dT0xNzMwMzI1Mjc3NDcwODA4MTA2O2g9ZmRkODI1Y2YzZjg1ZWI1MGFkMGU2NDRhMjExY2IzYjc=; suid=8ce6731f9a649540b81418dd7f7a116e.47f9f10efbd002c2a5df27708dee6294; _csrf_token=336e9598aa89701ea1d4a92ef74b8383aeb945805101384c; autoruuid=g6722ab1d22n1or4fd1vhlrpil0a28cb.27fdd35057ca4aa98e84995de580e2db; from=direct; autoru_sso_blocked=1; Session_id=3:1730325277.5.1.1661287478014:g-_qsg:7a.1.2:1|46441660.519755.2.2:519755|1130000067438128.-1.0.2:63503060.3:1724790538|61:10027023.161971.xI-XPxtAO96MYM_W4izayeiUh8Q; sessar=1.1195.CiAfLgyg5QFO9kv_v2Iwwkp6R5lIv6cePPCbuQfC79m-WA.NhwRXi6eFd_e185pyLkh8Ueus8HpDaU0f9XAxY7snJk; yandex_login=daboldyrev@edu.hse.ru; ys=udn.cDpkYWJvbGR5cmV2QGVkdS5oc2UucnU%3D#c_chck.2288135939; i=nzlq8Txl051mhytlolic3YKu6ZRZu7M23AglGQC2H6SChVI3I4dx9PEr/Dfs4y+y5EDaXVNKRdMgzgZN1dIUuL2Jc14=; yandexuid=8456723751661209048; L=AF8Ae2BiUUNFeWdaY0BiWHMBWQxYDglSIykrGSoFKgIoHhFWFCNAIBAtWhYf.1724955754.15868.39776.ae22e28e4e90f779e216b76750191ceb; mda2_beacon=1730325277687; sso_status=sso.passport.yandex.ru:synchronized; autoru_sso_redirect_blocked=1; crookie=Z1aKuGe6JLy4FKGXhIj3nnrehm9/YQjGl0VCNKR0jUKr7d2h3ivxaIYPu13wQXm619av9REd2gfP7/GSF9hkstsjJgk=; cmtchd=MTczMDMyNTI4MTY4NQ==; yaPassportTryAutologin=1; autoru_sid=123729954%7C1730325282210.7776000.jxWwPZ77fRVUIlfmhfmAtw.DItU0HaaGmmf9623BImFHi08A6jgdeS1mDF0pbX9qGc; popups-popup-guess-the-car-shown-count=1; _ym_d=1730325649; _yasc=pjX03g9KqviPlHjHOW4LvHXFlqUFi18/SLXJxQ60LnoY+pyRIcEArbgnLiJumj0F7zzKmA==; count-visits=5; from_lifetime=1730325650905; layout-config={\"screen_height\":900,\"screen_width\":1440,\"win_width\":876,\"win_height\":803}; cycada=Kx3ttLi+7hFZXHKh+gVBbnYzs+eP5+y9mEaD7l6eSdg='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки для подключения к сайту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем сведения из Headers при обращении к https://auto.ru/cars/used/ (зависят от браузера, компьютера), в том числе вводим cookies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.157032Z",
     "start_time": "2024-11-14T19:29:19.145926Z"
    }
   },
   "outputs": [],
   "source": [
    "# cookie = COOCIE_PC # с компьютера\n",
    "cookie = COOCIE_NB # с ноутбука\n",
    "\n",
    "headers = {\n",
    "    'authority': 'auto.ru',\n",
    "    'method': 'GET',\n",
    "    'path': '/cars/used/',\n",
    "    'scheme': 'https',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'accept-encoding': 'gzip, deflate, br, zstd',\n",
    "    'accept-language': 'ru,en;q=0.9,en-GB;q=0.8,en-US;q=0.7',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'cookie': cookie,\n",
    "    'priority': 'u=0, i',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"130\", \"Microsoft Edge\";v=\"130\", \"Not?A_Brand\";v=\"99\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform':'\"Windows\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции для сбора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.192427Z",
     "start_time": "2024-11-14T19:29:19.183799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая делает паузу случайной длительности\n",
    "def sleep():\n",
    "    random_seconds = np.linspace(3, 10, 100)\n",
    "    time.sleep(random.choice(random_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.338734Z",
     "start_time": "2024-11-14T19:29:19.327495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая загружает справочник комплектаций\n",
    "def open_complectation(file_name):\n",
    "    complectations = []\n",
    "    with open(file_name) as data:\n",
    "        for record in data:\n",
    "            res = {}\n",
    "            for paars in record[1:-2].split(\", '\"):\n",
    "                key, value = paars.split(\"':\")\n",
    "                value = value.replace(\"'\",\"\").strip()\n",
    "                if value == 'None':\n",
    "                    value = None\n",
    "                res[key.replace(\"'\",\"\").strip()] = value\n",
    "            complectations.append(res)\n",
    "    return complectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.407718Z",
     "start_time": "2024-11-14T19:29:19.371079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая загружает комплектацию модели\n",
    "# по адресу url_compl\n",
    "def get_complectation(url_compl):\n",
    "\n",
    "    # Немного подождали\n",
    "    sleep()\n",
    "    \n",
    "    # загрузили страницу с данными по автомобилю\n",
    "    page_compl = requests.get(url_compl, headers=headers)\n",
    "    \n",
    "    # получили иерархическое представление содержимого    \n",
    "    soup_compl = BeautifulSoup(page_compl.content, 'html.parser')\n",
    "\n",
    "    # Нашли нужный блок\n",
    "    card_info = soup_compl.find('div', {'class': 'ModificationInfo-GiDD1'})\n",
    "    \n",
    "    # создали словарь\n",
    "    row = {\n",
    "        'url_compl': url_compl,\n",
    "        'state_mark': None,\n",
    "        'class_auto': None,\n",
    "        'door_count': None,\n",
    "        'seat_count': None,\n",
    "        'long': None,\n",
    "        'width': None,\n",
    "        'height': None,\n",
    "        'clearence': None,\n",
    "        'v_bag': None,\n",
    "        'v_tank': None,\n",
    "        'curb_weight': None,\n",
    "        'gross_weight': None,\n",
    "        'front_brakes': None,\n",
    "        'rear_brakes': None,\n",
    "        'max_speed': None,\n",
    "        'acceleration': None,\n",
    "        'fuel_cons': None,\n",
    "        'fuel_brand': None,\n",
    "        'engine_loc1': None,\n",
    "        'engine_loc2': None,\n",
    "        'turbocharg': None,\n",
    "        'max_torq': None,\n",
    "        'cyl_count': None\n",
    "        }\n",
    "    \n",
    "    # извлекли сведения о комплектации\n",
    "    for li in card_info.find_all('li'): \n",
    "        li_span = li.find('span').text.strip()\n",
    "        match li_span:\n",
    "            case 'Страна марки':\n",
    "                try:\n",
    "                    row['state_mark'] = li.find_all('span')[1].text.strip().replace('\\xa0',' ')\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Класс автомобиля':\n",
    "                try:\n",
    "                    row['class_auto'] = li.find_all('span')[1].text.strip().replace('\\xa0',' ')\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Количество дверей':\n",
    "                try:\n",
    "                    row['door_count'] = li.find_all('span')[1].text.strip().strip()\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Количество мест':\n",
    "                try:\n",
    "                    row['seat_count'] = li.find_all('span')[1].text.strip().strip()\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Длина':\n",
    "                try:\n",
    "                    row['long'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Ширина':\n",
    "                try:\n",
    "                    row['width'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Высота':\n",
    "                try:\n",
    "                    row['height'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Клиренс':\n",
    "                try:\n",
    "                    row['clearence'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Объем багажника':\n",
    "                try:\n",
    "                    row['v_bag'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Объём топливного':\n",
    "                try:\n",
    "                    row['v_tank'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Снаряженная масса':\n",
    "                try:\n",
    "                    row['curb_weight'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Полная масса':\n",
    "                try:\n",
    "                    row['gross_weight'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Передние тормоза':\n",
    "                try:\n",
    "                    row['front_brakes'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Задние тормоза':\n",
    "                try:\n",
    "                    row['rear_brakes'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Максимальная скорость':\n",
    "                try:\n",
    "                    row['max_speed'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Разгон':\n",
    "                try:\n",
    "                   row['acceleration'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Расход топлива':\n",
    "                try:\n",
    "                    row['fuel_cons'] = li.find_all('span')[1].text.strip().split('/')[1]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Марка топлива':\n",
    "                try:\n",
    "                    row['fuel_brand'] = li.find_all('span')[1].text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Расположение двигателя':\n",
    "                try:\n",
    "                    row['engine_loc1'] = li.find_all('span')[1].text.strip().split(', ')[0]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    row['engine_loc2'] = li.find_all('span')[1].text.strip().split(', ')[1]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Тип наддува':\n",
    "                try:\n",
    "                    row['turbocharg'] = li.find_all('span')[1].text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Максимальный крутящий':\n",
    "                try:\n",
    "                    row['max_torq'] = li.find_all('span')[1].text.strip().split()[0]\n",
    "                except:\n",
    "                    pass\n",
    "            case 'Количество цилиндров':\n",
    "                try:\n",
    "                    row['cyl_count'] = li.find_all('span')[1].text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            case _:\n",
    "                pass\n",
    "    # передали словарь\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.456726Z",
     "start_time": "2024-11-14T19:29:19.413788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая загружает данные из объявления\n",
    "# по адресу url_car\n",
    "def get_car(url_car):    \n",
    "\n",
    "    # Немного подождали\n",
    "    sleep()\n",
    "    \n",
    "    # зададим год, в котором опубликованы объявления\n",
    "    year = 2024\n",
    "    \n",
    "    # Зададим количество л.с. в 1 кВт\n",
    "    HP_per_kW = 1.3596216173\n",
    "    \n",
    "    # подготовили словарь для месяцев\n",
    "    dict_month = {\n",
    "        'января': 1,\n",
    "        'февраля': 2,\n",
    "        'марта': 3,\n",
    "        'апреля': 4,\n",
    "        'мая': 5,\n",
    "        'июня': 6,\n",
    "        'июля': 7,\n",
    "        'августа': 8,\n",
    "        'сентября': 9,\n",
    "        'октября': 10,\n",
    "        'ноября': 11,\n",
    "        'декабря':12\n",
    "    }\n",
    "    \n",
    "    # создали словарь для объявления\n",
    "    row = {\n",
    "        'url_car': url_car,\n",
    "        'car_make': None,\n",
    "        'car_model': None,\n",
    "        'car_gen': None,\n",
    "        'car_type': None,\n",
    "        'car_compl': None,\n",
    "        'ann_date': None,\n",
    "        'ann_id': None,\n",
    "        'car_price': None,\n",
    "        'ann_city': None,\n",
    "        'link_cpl': None,\n",
    "        'avail': None,\n",
    "        'year': None,\n",
    "        'mileage': None,\n",
    "        'color': None,\n",
    "        'eng_size': None,\n",
    "        'eng_power': None,\n",
    "        'eng_power_kw': None,\n",
    "        'eng_type': None,\n",
    "        'pow_resrv': None,\n",
    "        'options': None,\n",
    "        'transmission': None,\n",
    "        'drive': None,\n",
    "        'st_wheel': None,\n",
    "        'condition': None,\n",
    "        'count_owner': None,\n",
    "        'original_pts': None,\n",
    "        'customs': None\n",
    "        }\n",
    "\n",
    "    # загрузили страницу с данными по автомобилю\n",
    "    page_auto = requests.get(url_car, headers=headers)\n",
    "        \n",
    "    # получили иерархическое представление содержимого\n",
    "    soup_auto = BeautifulSoup(page_auto.content, 'html.parser')\n",
    "\n",
    "    # извлекли данные из блока CardBreadcrumbs\n",
    "    CardBreadcrums = soup_auto.find('div', {'class': 'CardBreadcrumbs'})\n",
    "    row['car_make'] = CardBreadcrums.find_all('a')[2].text\n",
    "    row['car_model'] = CardBreadcrums.find_all('a')[3].text\n",
    "    row['car_gen'] = CardBreadcrums.find_all('a')[4].text\n",
    "    row['car_type'] = CardBreadcrums.find_all('a')[5].text\n",
    "    row['car_compl'] = CardBreadcrums.find_all('a')[6].text\n",
    "\n",
    "    # извлекли данные об объявлении\n",
    "    ann_date = soup_auto.find('div', {'class': 'CardHead__infoItem CardHead__creationDate'}).text.strip().split()\n",
    "    row['ann_date'] = str(date(year, dict_month[ann_date[1]], int(ann_date[0])))\n",
    "    row['ann_id'] = soup_auto.find('div', {'class': 'CardHead__infoItem CardHead__id'}).text.strip()[2:]\n",
    "    row['car_price'] = int(soup_auto.find('span', {'class': 'OfferPriceCaption__price'}).text.replace('\\xa0','')[:-1])\n",
    "    row['ann_city'] = soup_auto.find('span', {'class': 'MetroListPlace__regionName MetroListPlace_nbsp'}).text\n",
    "        \n",
    "\n",
    "    card_info = soup_auto.find('div', {'class': 'CardInfo-ateuv'})\n",
    "\n",
    "    # записали ссылку на комплектацию\n",
    "    for a in soup_auto.find_all('a'):\n",
    "        if 'Характеристики модели' in a.text:\n",
    "            row['link_cpl'] = a.get('href')\n",
    "        \n",
    "    # извлекли сведения об автомобиле\n",
    "    row['avail'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_availability'}).find_all('div')[1].text.replace('\\xa0',' ')\n",
    "    row['year'] = int(card_info.find('li', {'class': 'CardInfoRow CardInfoRow_year'}).find_all('div')[1].text)\n",
    "    row['mileage'] = int(card_info.find('li', {'class': 'CardInfoRow CardInfoRow_kmAge'}).find_all('div')[1].text.replace('\\xa0','')[:-3])\n",
    "    row['color'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_color'}).find_all('div')[1].text\n",
    "    if card_info.find('li', {'class': 'CardInfoRow CardInfoRow_engine'}).find_all('div')[1].text.split(' / ')[2] == 'Электро':\n",
    "        # eng_size остаётся None для электромобилей\n",
    "        eng_data = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_engine'}).find_all('div')[1].text.split(' / ')\n",
    "        row['eng_power_kw'] = int(eng_data[1].split()[0])\n",
    "        row['eng_power'] = int(HP_per_kW * row['eng_power_kw'])        \n",
    "        row['pow_resrv'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_electricRange'}).find_all('div')[1].text.split()[0]\n",
    "    else:\n",
    "        # pow_resrv остаётся None для авто с ДВС\n",
    "        eng_data = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_engine'}).find_all('div')[1].text.split(' / ')\n",
    "        row['eng_size'] = float(eng_data[0].split()[0])\n",
    "        row['eng_power'] = int(eng_data[1].split()[0])\n",
    "        row['eng_power_kw'] = int(row['eng_power'] / HP_per_kW)\n",
    "    row['eng_type'] = eng_data[2]\n",
    "    row['options'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_complectationOrEquipmentCount'}).find_all('div')[1].text.strip().replace('\\xa0',' ')\n",
    "    row['transmission'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_transmission'}).find_all('div')[1].text\n",
    "    row['drive'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_drive'}).find_all('div')[1].text\n",
    "    row['st_wheel'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_wheel'}).find_all('div')[1].text\n",
    "    row['condition'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_state'}).find_all('div')[1].text\n",
    "    try:\n",
    "        row['count_owner'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_ownersCount'}).find_all('div')[1].text.replace('\\xa0',' ')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        row['original_pts'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_pts'}).find_all('div')[1].text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        row['customs'] = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_customs'}).find_all('div')[1].text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if row['link_cpl'] in list(map(lambda x: x['url_compl'], complectations)):\n",
    "\n",
    "        # добавили сведения из ранее загруженной комплектации\n",
    "        for record in complectations:\n",
    "            if row['link_cpl'] == record['url_compl']:\n",
    "                row = {**row, **record}\n",
    "    else:       \n",
    "        # добавили сведения из комплектации\n",
    "        record = get_complectation(row['link_cpl'])\n",
    "        complectations.append(record)\n",
    "        with open('data_comp_dmitrii.txt', 'a') as data_comp:\n",
    "            print(record, file=data_comp)\n",
    "        row = {**row, **record}\n",
    "    \n",
    "    # передаем словарь\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.488899Z",
     "start_time": "2024-11-14T19:29:19.475706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая создаёт и возвращает список марок автомобилей,\n",
    "# первая буква названия которых находится в диапазоне от a до b (параметры)\n",
    "def get_page_makes(a, b):\n",
    "\n",
    "    # изготовили ссылку на страницу списка с объявлениями\n",
    "    url = 'https://auto.ru/catalog/cars/'\n",
    "\n",
    "    # немного подождали\n",
    "    sleep()\n",
    "\n",
    "    # сходили по ней\n",
    "    page_list = requests.get(url, headers=headers)\n",
    "\n",
    "    # получили иерархическое представление содержимого\n",
    "    soup = BeautifulSoup(page_list.content, 'html.parser')\n",
    "\n",
    "    # ищем тут CatalogFilterSearchList__hidden-stSPU\n",
    "    card_info = soup.find('div', {'class': 'CatalogFilterSearchList__hidden-stSPU'})\n",
    "\n",
    "    # нашли в нём марки авто, записали в список\n",
    "    name_makes = []\n",
    "    for link in card_info.find_all('a'):\n",
    "        if link.get('href'):\n",
    "            name_makes.append(link.get('href').split('/')[-2])\n",
    "    \n",
    "    # убрали дубли\n",
    "    name_makes = list(set(name_makes))\n",
    "    \n",
    "    # отсортировали по афавиту\n",
    "    name_makes.sort()\n",
    "\n",
    "    # оставили марки из диапазона\n",
    "    name_makes = list(filter(lambda x: (ord(x[0]) >= ord(a) and ord(x[0]) <= ord(b)), name_makes))\n",
    "    \n",
    "    return name_makes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.549213Z",
     "start_time": "2024-11-14T19:29:19.535426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая загружает объявления с одной\n",
    "# из страниц выдачи объявлений определённой марки автомобилей\n",
    "def get_page(make, p):\n",
    "    # изготовили ссылку на страницу списка с объявлениями\n",
    "    url_base = f'https://auto.ru/cars/{make}/used/'\n",
    "    if p ==1:\n",
    "        url = f'{url_base}'\n",
    "    else:\n",
    "        url = f'{url_base}?page={p}'\n",
    "\n",
    "    # немного подождали\n",
    "    sleep()\n",
    "\n",
    "    # сходили по ней\n",
    "    page_list = requests.get(url, headers=headers)\n",
    "\n",
    "    # получили иерархическое представление содержимого\n",
    "    soup = BeautifulSoup(page_list.content, 'html.parser')\n",
    "\n",
    "    # нашли в нём ссылки на авто, записали в список\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.get('href') != None and 'cars/used/sale' in link.get('href') and link.get('href') not in urls:\n",
    "            urls.append(link.get('href'))\n",
    "\n",
    "    # прошли по ссылкам записали данные в список словарей\n",
    "    info = []\n",
    "    mistakes = []\n",
    "\n",
    "    # включаем счетчики\n",
    "    success = 0\n",
    "    failure = 0\n",
    "    t = tqdm(urls, desc=f'Загрузка {name_make}/{page}. Успешно: {success}. Ошибок: {failure}')\n",
    "    for link in t:\n",
    "        try:\n",
    "            info.append(get_car(link))\n",
    "            success += 1\n",
    "        except:\n",
    "            mistakes.append(link)\n",
    "            failure += 1\n",
    "        t.set_description(f'Загрузка {name_make}/{page}. Успешно: {success}. Ошибок: {failure}')\n",
    "        t.refresh()\n",
    "\n",
    "    return info, success, failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:29:19.620713Z",
     "start_time": "2024-11-14T19:29:19.610039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Определим функцию, которая определяет количество объявлений\n",
    "# для определённой марки автомобиля\n",
    "def get_page_models(name_make):\n",
    "\n",
    "    # изготовили ссылку на страницу списка с объявлениями\n",
    "    url = f'https://auto.ru/cars/{name_make}/used/'\n",
    "    \n",
    "    # немного подождали\n",
    "    sleep()\n",
    "    \n",
    "    # сходили по ней\n",
    "    page_list = requests.get(url, headers=headers)\n",
    "\n",
    "    # получили иерархическое представление содержимого\n",
    "    soup = BeautifulSoup(page_list.content, 'html.parser')\n",
    "\n",
    "    # Ищем тут ButtonWithLoader__inner\n",
    "    model_info = soup.find('div', {'class': 'ButtonWithLoader__inner'})\n",
    "\n",
    "    # определили количество объявлений\n",
    "    summ = int(''.join(model_info.text.split()[1:-1]))\n",
    "        \n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Определим функцию, которая открывает и считывает данные\n",
    "# из текстового файла и возвращает датасет\n",
    "def open_data(file_name):\n",
    "    data_cars = []\n",
    "    with open(f'{file_name}', 'r') as data:\n",
    "        ann_ids = set()\n",
    "        for record in data:\n",
    "            res = {}\n",
    "            for paars in record[1:-2].split(\", '\"):\n",
    "                key, value = paars.split(\"':\")\n",
    "                value = value.replace(\"'\",\"\").strip()\n",
    "                if value == 'None':\n",
    "                    value = None\n",
    "                res[key.replace(\"'\",\"\").strip()] = value\n",
    "            if res['ann_id'] not in ann_ids:\n",
    "                data_cars.append(res)\n",
    "                ann_ids.add(res['ann_id'])\n",
    "    return pd.DataFrame(data_cars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:34:07.865057Z",
     "start_time": "2024-11-14T19:34:07.853390Z"
    }
   },
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор данных с сайта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-11T23:01:00.034090Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a36fcccdd5f4d51b3b37096d535b385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Загрузка u - z. Успешно: 0. Ошибок: 0:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72f0703cdb0422bb4d5069930318967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Загрузка uaz. Успешно: 0. Ошибок: 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4de644309e4884af4805c7a7d5b99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Загрузка uaz/1. Успешно: 0. Ошибок: 0:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузим имеющиеся сведения о комплектациях\n",
    "data_comp = 'data_comp_dmitrii.txt'\n",
    "try:\n",
    "    with open('log_dmitrii.txt', 'a') as log:\n",
    "        complectations = open_complectation(data_comp)\n",
    "        print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Загружен файл с комплектацией {data_comp}', file=log)\n",
    "except (FileNotFoundError, PermissionError):\n",
    "    complectations = []\n",
    "    with open('log_dmitrii.txt', 'a') as log:\n",
    "        print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Не был загружен файл с комплектацией {data_comp}', file=log)\n",
    "\n",
    "# Загружаем наименования марок автомобилей\n",
    "s_letter = 'u'\n",
    "f_letter = 'z'\n",
    "name_makes = get_page_makes(s_letter, f_letter)\n",
    "\n",
    "# включаем счетчики\n",
    "success_all = 0\n",
    "failure_all = 0\n",
    "\n",
    "# Запускаем цикл с перебором марок автомобилей\n",
    "t_make = tqdm(name_makes, desc=f'Загрузка {s_letter} - {f_letter}. Успешно: {success_all}. Ошибок: {failure_all}')\n",
    "for name_make in t_make:\n",
    "\n",
    "    # Вычисляем количество страниц для загрузки по марке (не более 100)\n",
    "    try:\n",
    "        count_page = get_page_models(name_make) // 38 + 2\n",
    "        count_page = min(count_page, 100)\n",
    "    except:\n",
    "        count_page = 1\n",
    "\n",
    "    # включаем счетчики\n",
    "    success_make = 0\n",
    "    failure_make = 0\n",
    "\n",
    "    # Запускаем цикл с перебором страниц марки\n",
    "    t = tqdm(range(1, count_page), desc=f'Загрузка {name_make}. Успешно: {success_make}. Ошибок: {failure_make}')\n",
    "    for page in t:\n",
    "        try:\n",
    "            # Загружаем сведения об автомобиле\n",
    "            date_page = get_page(name_make, page)\n",
    "            success_make += date_page[1]\n",
    "            success_all += date_page[1]\n",
    "            failure_make += date_page[2]\n",
    "            failure_all += date_page[2]\n",
    "\n",
    "            # Обновляем информацию в прогресс-баре\n",
    "            t.set_description(f'Загрузка {name_make}. Успешно: {success_make}. Ошибок: {failure_make}')\n",
    "            t.refresh()\n",
    "            with open('data_dmitrii.txt', 'a') as data:\n",
    "                for record in date_page[0]:\n",
    "                    print(record, file=data)\n",
    "            with open('log_dmitrii.txt', 'a') as log:\n",
    "                print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Успешно загружена страница {name_make}/{page}. Число добавленных записей {len(date_page[0])}', file=log)\n",
    "        except:\n",
    "            with open('log_dmitrii.txt', 'a') as log:\n",
    "                print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Не была загружена страница {name_make}/{page}. Число добавленных записей {0}', file=log)\n",
    "\n",
    "    \n",
    "    # Обновляем информацию в прогресс-баре   \n",
    "    t_make.set_description(f'Загрузка {s_letter} - {f_letter}. Успешно: {success_all}. Ошибок: {failure_all}')\n",
    "    t_make.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Разбор и сохранение загруженных данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:24:08.640872Z",
     "start_time": "2024-11-14T19:24:08.367692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1904"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получим датасет из новой порции данных\n",
    "new_data = open_data('data_dmitrii.txt')\n",
    "print(new_data.shape)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Откроем имеющийся датасет, полученный ранее\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, 'data_dmitrii.csv')\n",
    "print(data.shape)\n",
    "data.head()                   "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Объединим имеющийся датасет с новым\n",
    "data = pd.concat([data, new_data], axis=0).reset_index()\n",
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T18:48:51.905886Z",
     "start_time": "2024-11-14T18:48:42.041933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Сохраним расширенный датасет, возможно, поменяв имя файла\n",
    "pd.to_csv(os.path.join(DATA_PATH, input('file_name?')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:21:23.778479Z",
     "start_time": "2024-11-14T19:21:23.696975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Обновим файл с комплектациями\n",
    ".to_csv(os.path.join(DATA_PATH, 'complectations_dmitrii.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
